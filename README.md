# ECE209AS-AI-ML_CPS-IoT in red

<p style='color:red'> Project for ECE 209-AS for Winter 2021 </p>

## Team Members:
Riyya Hari Iyer (Department of Electrical and Computer Engineering, UCLA 2021)

Matthew Nicholas (Department of Electrical and Computer Engineering, UCLA 2021)

## Project Proposal

This project will focus on improving real-time video inferences on compute-limited edge devices. Common video inference tasks such as object detection, semantic segmentation and pose estimation typically empoloy the use of Deep Neural Networks (DNNs). However, these DNNs have a substantial memory footprint and require significant compute capabilities that are not present on many resource-constrained edge devices. In order to perform these tasks on those edge devices it is common to either (1) employ a specialized "lightweight" model or (2) offload compute to a remote server. 
In their paper, "Real-Time Video Inference on Edge Devices via Adaptive Model Streaming", Khani et al. propose ...

We are currently working on a project where we aim to implement object detection using microcontrollers. Broadly speaking, we aim to implement deep learning models such as RNNs and CNNs on memory-constrained devices like microcontroller (Arduino Nano specifically) and use them to facilitate object detection. Given below are some papers that we would refer to.

## References
[1] Khani, M., Hamadanian, P., Nasr-Esfahany, A. and Alizadeh, M., 2020. Real-Time Video Inference on Edge Devices via Adaptive Model Streaming. arXiv preprint arXiv:2006.06628.
